{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0a11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef09ee",
   "metadata": {},
   "source": [
    "## 1. 超参数 & 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd116195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "max_input_len = 512\n",
    "max_target_len = 64\n",
    "num_epochs = 4\n",
    "learning_rate = 2e-5\n",
    "seed = 42\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8971f0",
   "metadata": {},
   "source": [
    "## 2. 数据加载 & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f62e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train dataset: 14520\n",
      "length of valid dataset: 984\n",
      "{'context': '第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。', 'question': '仙剑奇侠传3第几集上天界', 'answer': '第35集'}\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl(path):\n",
    "    examples = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            examples.append(json.loads(line.strip()))\n",
    "    return examples\n",
    "\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"context\":  item[\"context\"],\n",
    "            \"question\": item[\"question\"],\n",
    "            \"answer\":   item[\"answer\"],\n",
    "        }\n",
    "\n",
    "\n",
    "train_data = load_jsonl('./DuReaderQG/train.json')\n",
    "valid_data = load_jsonl('./DuReaderQG/dev.json')\n",
    "train_dataset = QADataset(train_data)\n",
    "valid_dataset = QADataset(valid_data)\n",
    "print(f\"length of train dataset: {len(train_dataset)}\")\n",
    "print(f\"length of valid dataset: {len(valid_dataset)}\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919297f",
   "metadata": {},
   "source": [
    "## 3. Tokenizer 和 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d7d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"../mengzi-t5-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(checkpoint, use_fast=False)\n",
    "model      = AutoModelForSeq2SeqLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8196bde",
   "metadata": {},
   "source": [
    "## 4. collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19e661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch_sample):\n",
    "    inputs  = [f\"question: {example['question']}  context: {example['context']}\" for example in batch_sample]\n",
    "    targets = [example[\"answer\"] for example in batch_sample]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_input_len,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=max_target_len,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).input_ids\n",
    "\n",
    "    # 把[PAD]的id换成-100， 训练时忽略\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7a447",
   "metadata": {},
   "source": [
    "## 5. compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b189901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # 把 -100 还原成 pad_id，再 decode references\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    references = [decoded_refs]\n",
    "\n",
    "    bleu = sacrebleu.corpus_bleu(decoded_preds, references, force=True)\n",
    "    return {\n",
    "        \"bleu\":   np.mean(bleu.precisions) / 100,\n",
    "        \"bleu-1\": bleu.precisions[0] / 100,\n",
    "        \"bleu-2\": bleu.precisions[1] / 100,\n",
    "        \"bleu-3\": bleu.precisions[2] / 100,\n",
    "        \"bleu-4\": bleu.precisions[3] / 100,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85bb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11月8日至14日', '比尔', '到东莞的距离', '其原创性及文中陈述内容未经本站证实,部分内容的真实性、完整性、及时性不作任何保证和承诺。']\n",
      "[['2002年11月8日至14日', '比尔·拉塞尔', '南宁至东莞的距离', '其原创性及文中陈述内容未经本站证实,本地宝对本文及其中全部或者部分内容的真实性、完整性、及时性不作任何保证和承诺,请网友自行核实相关内容。']]\n",
      "33.333333333333336\n",
      "[33.333333333333336, 50.0, 50.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# text = [\"2002年11月8日至14日\", \"比尔·拉塞尔\", \"南宁至东莞的距离\", \"其原创性及文中陈述内容未经本站证实,本地宝对本文及其中全部或者部分内容的真实性、完整性、及时性不作任何保证和承诺,请网友自行核实相关内容。\"]\n",
    "# preds_biased = [\"11月8日至14日\", \"比尔\", \"到东莞的距离\", \"其原创性及文中陈述内容未经本站证实,部分内容的真实性、完整性、及时性不作任何保证和承诺。\"]\n",
    "# source = [text]\n",
    "# input = tokenizer(text,\n",
    "#                   padding=True,\n",
    "#                   truncation=True,\n",
    "#                   max_length = max_input_len,\n",
    "#                   return_tensors=\"pt\")[\"input_ids\"]\n",
    "# preds = tokenizer.batch_decode(input, skip_special_tokens=True)\n",
    "# bleu = sacrebleu.corpus_bleu(preds_biased, source, force=True)\n",
    "# print(preds_biased)\n",
    "# print(source)\n",
    "# print(np.mean(bleu.precisions))\n",
    "# print(bleu.precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78903e5e",
   "metadata": {},
   "source": [
    "## 6. 配置trainingarguments & trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77343fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./outputs\",\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"bleu\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    predict_with_generate=True,          # 让 Trainer 调用 model.generate\n",
    "    generation_num_beams=5,\n",
    "    generation_max_length=max_target_len,\n",
    "\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c13a395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "d:\\miniconda3\\envs\\tran\\lib\\site-packages\\transformers\\trainer.py:474: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e02cf",
   "metadata": {},
   "source": [
    "## 7. 训练 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(\"[FINAL EVAL]\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./final_model\")\n",
    "tokenizer.save_pretrained(\"./final_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tran",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
